# -*- coding: utf-8 -*-
"""chatbot using llama-index.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VRJVK-k19V50bwK1ejMecE9LbO27L2vd
"""

!nvidia-smi

pip install openai

pip install colab-env --upgrade

import colab_env


OPENAI_API_KEY = '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'

colab_env.envvar_handler.add_env("OPENAI_API_KEY", "envalue", overwrite=True)

import os
import openai
#OPENAI_API_KEY = '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'
#openai.api_key = os.getenv("OPENAI_API_KEY")
#openai.Model.list()

pip install -q langchain transformers sentence_transformers llama-index

pip install llama-index

from zipfile import ZipFile

# loading the temp.zip and creating a zip object
with ZipFile("/content/ankit.zip", 'r') as zObject:

    # Extracting all the members of the zip
    # into a specific location.
    zObject.extractall(
        path="/content/ankit")



from llama_index import SimpleDirectoryReader,LLMPredictor
from llama_index import GPTListIndex,LangchainEmbedding
from langchain.llms.base import LLM
from transformers import pipeline
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
import torch
from llama_index import VectorStoreIndex
import os
from langchain import OpenAI
import openai
import colab_env

os.environ['OPENAI_API_KEY'] = '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'

# importing the zipfile module


class customLLM(LLM):
    model_name = "google/flan-t5-large"
    pipeline = pipeline("text2text-generation", model=model_name, device=0, model_kwargs={"torch_dtype":torch.bfloat16})

    def _call(self, prompt, stop=None):
        return self.pipeline(prompt, max_length=9999)[0]["generated_text"]

    def _identifying_params(self):
        return {"name_of_model": self.model_name}

    def _llm_type(self):
        return "custom"

num_outputs = 300


llm_predictor = LLMPredictor(llm = customLLM())

hfemb = HuggingFaceEmbeddings()
embed_model = LangchainEmbedding(hfemb)

OPENAI_API_KEY = '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'
openai.api_key = os.getenv('OPENAI_API_KEY')

documents = SimpleDirectoryReader('/content/ankit/dialogs.txt').load_data()
#documents = SimpleDirectoryReader('data').load_data()
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine()
response = query_engine.query("What did the author do growing up?")
print(response)

index = VectorStoreIndex.from_documents( documents,embed_model = embed_model, llm_predictore = llm_predictor , openai_api_key=os.environ['OPENAI_API_KEY'])
query_engine = index.as_query_engine()
response = query_engine.query("What up?")

#response = index.query("Write an email to the user given their background information.")
print(response)
#response = index.query("<hello>", mode="default")